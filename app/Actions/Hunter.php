<?php

namespace App\Actions;

use DOMDocument;
use DOMXPath;
use GuzzleHttp\Exception\RequestException;
use Illuminate\Support\Facades\File;
use Illuminate\Support\Facades\Log;
use Psr\Http\Message\ResponseInterface;
use Psr\Http\Message\UriInterface;
use Spatie\Browsershot\Exceptions\CouldNotTakeBrowsershot;
use Spatie\Crawler\CrawlObservers\CrawlObserver;
use Spatie\Browsershot\Browsershot;

class Hunter extends CrawlObserver
{

    public function willCrawl(UriInterface $url)
    {
        parent::willCrawl($url); // TODO: Change the autogenerated stub
        echo "Now crawling: " . (string) $url . PHP_EOL;
    }

    /**
     * @var String
     */
    private $project;

    public function __construct(String $project)
    {
        $this->project = $project;
    }

    /**
     * @throws CouldNotTakeBrowsershot
     */
    public function crawled(UriInterface $url, ResponseInterface $response, ?UriInterface $foundOnUrl = null)
    {
        $doc = new DOMDocument();
        @$doc->loadHTML($response->getBody());
        $finder = new DomXPath(@$doc);
        $json = File::get("storage/sites.json");
        $sites = json_decode($json, true);
        $nodes = $finder->query($sites[$this->project]);

        foreach ($nodes as $node) {
            $url = 'https://' . $this->project . $node->attributes['href']->value;
            $url = rawurldecode($url);
            Log::info($url);
            Browsershot::url($url)
                ->format('A4')
                ->save(storage_path('PDF/' . $this->project . '/' . basename($url) . '.pdf'));
        }



    }

    public function crawlFailed(UriInterface $url, RequestException $requestException, ?UriInterface $foundOnUrl = null)
    {
        // TODO: Implement crawlFailed() method.
    }

    public function finishedCrawling()
    {
        parent::finishedCrawling(); // TODO: Change the autogenerated stub
    }
}

